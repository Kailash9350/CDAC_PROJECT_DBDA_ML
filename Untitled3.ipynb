{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a851a47-4608-4427-bfd0-f697c37f8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'reviews': [\n",
    "        'The movie was fantastic and thrilling',\n",
    "        'Worst movie ever, bad acting',\n",
    "        'An average storyline but great visuals'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'neutral']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1533e785-8a96-4561-8359-d94d341d45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['tokens'] = df['reviews'].apply(lambda x: word_tokenize(x.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d506e4-dd50-49d2-833e-d78b1a20873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3.tar.gz (23.3 MB)\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 2.1/23.3 MB 10.9 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 4.7/23.3 MB 11.8 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 7.3/23.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 9.7/23.3 MB 12.1 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 12.8/23.3 MB 12.6 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 16.3/23.3 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 19.1/23.3 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 22.5/23.3 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 23.3/23.3 MB 13.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 3.1/15.8 MB 15.2 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 6.3/15.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 9.7/15.8 MB 15.4 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 12.8/15.8 MB 15.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.7/15.8 MB 15.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.8/15.8 MB 14.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [22 lines of output]\n",
      "  + C:\\Users\\kaila\\AppData\\Local\\Programs\\Python\\Python313\\python.exe C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\\vendored-meson\\meson\\meson.py setup C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325 C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\\.mesonpy-ky9c41fw -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\\.mesonpy-ky9c41fw\\meson-python-native-file.ini\n",
      "  The Meson build system\n",
      "  Version: 1.2.99\n",
      "  Source dir: C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\n",
      "  Build dir: C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\\.mesonpy-ky9c41fw\n",
      "  Build type: native build\n",
      "  Project name: NumPy\n",
      "  Project version: 1.26.4\n",
      "  C compiler for the host machine: gcc (gcc 9.2.0 \"gcc (tdm-1) 9.2.0\")\n",
      "  C linker for the host machine: gcc ld.bfd 2.32\n",
      "  C++ compiler for the host machine: c++ (gcc 9.2.0 \"c++ (tdm-1) 9.2.0\")\n",
      "  C++ linker for the host machine: c++ ld.bfd 2.32\n",
      "  Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "  Host machine cpu family: x86\n",
      "  Host machine cpu: x86\n",
      "  Program python found: YES (C:\\Users\\kaila\\AppData\\Local\\Programs\\Python\\Python313\\python.exe)\n",
      "  Need python for x86, but found x86_64\n",
      "  Run-time dependency python found: NO (tried sysconfig)\n",
      "  \n",
      "  ..\\meson.build:41:12: ERROR: Python dependency not found\n",
      "  \n",
      "  A full log can be found at C:\\Users\\kaila\\AppData\\Local\\Temp\\pip-install-2espzu9f\\numpy_66a6f414d7ef46af9a672307e6ca8325\\.mesonpy-ky9c41fw\\meson-logs\\meson-log.txt\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4750f095-4087-46d3-b3b3-2c050182c2ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Word2Vec trains on list of token lists\u001b[39;00m\n\u001b[32m      4\u001b[39m w2v_model = Word2Vec(sentences=df[\u001b[33m'\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m'\u001b[39m], vector_size=\u001b[32m100\u001b[39m, window=\u001b[32m5\u001b[39m, min_count=\u001b[32m1\u001b[39m, workers=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Word2Vec trains on list of token lists\n",
    "w2v_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a0adf-01a4-482d-9a59-cc0a9e6320a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df['review_vector'] = df['tokens'].apply(lambda x: get_avg_vector(x, w2v_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052dfa9a-c3e7-444a-8a34-262e9cf71bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   reviews sentiment  char_count  word_count  \\\n",
      "0   The movie was fantastic and thrilling!  positive        38.0         7.0   \n",
      "1           Worst movie ever, bad acting!!  negative        30.0         8.0   \n",
      "2  An average storyline but great visuals.   neutral        39.0         7.0   \n",
      "\n",
      "   avg_word_len  polarity  subjectivity  exclamations  questions  \n",
      "0      5.428571  0.356250      0.950000           1.0        0.0  \n",
      "1      3.750000 -0.566667      0.555556           2.0        0.0  \n",
      "2      5.571429  0.325000      0.575000           0.0        0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'reviews': [\n",
    "        'The movie was fantastic and thrilling!',\n",
    "        'Worst movie ever, bad acting!!',\n",
    "        'An average storyline but great visuals.'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'neutral']\n",
    "})\n",
    "\n",
    "def extract_features(review):\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    length = len(review)\n",
    "    word_count = len(tokens)\n",
    "    avg_word_len = length / word_count if word_count > 0 else 0\n",
    "    blob = TextBlob(review)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    exclamations = review.count('!')\n",
    "    questions = review.count('?')\n",
    "    \n",
    "    return pd.Series([length, word_count, avg_word_len, polarity, subjectivity, exclamations, questions])\n",
    "\n",
    "df[['char_count', 'word_count', 'avg_word_len', 'polarity', 'subjectivity', 'exclamations', 'questions']] = df['reviews'].apply(extract_features)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887303bd-51ad-45f7-bb4b-ad9d7cedc04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
